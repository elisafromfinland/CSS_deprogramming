{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "import statistics \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "#!pip install scipy\n",
    "import scipy\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Session 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we load our tweets data and\n",
    "# open a csv datafile to make a dataframe\n",
    "tweets_df = pd.read_csv('tweets.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     54\n",
       "1     83\n",
       "2    140\n",
       "3    140\n",
       "4    279\n",
       "5    139\n",
       "6     94\n",
       "7    140\n",
       "8    140\n",
       "9    140\n",
       "Name: display_text_width, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Like yesterday for the following exercises we will use a subset of the data. Simply the first 10 observations from the variable \n",
    "# 'display_text_width'. \n",
    "\n",
    "xs_data = tweets_df['display_text_width'][:10]\n",
    "xs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Variance & standard deviation\n",
    "\n",
    "Moving forward from yesterday, once we have described the central tendency of the data, we often also want to describe how variable the data are – this is sometimes also referred to as “dispersion”, reflecting the fact that it describes how widely dispersed the data are. Two common dispersion measures are the variance and the standard deviation. \n",
    "\n",
    "The variance for a population (referred to as  $\\sigma ^2$) is the sum of the squared differences between each data point and the mean divided by the number of observations:\n",
    "$$\\frac{\\sum_{i=1}^n (x_i - \\mu)^2}{n-1}$$\n",
    "\n",
    "The standard deviation (referred to as  $\\sigma$) is simply the square root of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the variance and standard deviation of xs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p> Solution </p>\n",
    "\n",
    "First steps: You do not need to code this in Python, simply attempt to describe the steps. For instance, to obtain the variance and standard deviation of our xs_data dataset we would: ...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily for us, there are quicker ways to calculate all this statistics in Python. We could, for example, use already existing functions from the package Numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3535.8777777777777"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.var(xs_data, ddof=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59.46324728584689"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(xs_data, ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Covariance and correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       8\n",
       "1       4\n",
       "2     973\n",
       "3     817\n",
       "4      10\n",
       "5     619\n",
       "6      55\n",
       "7     744\n",
       "8    2232\n",
       "9      73\n",
       "Name: retweet_count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will introduce a second set of small data in order to introduce the covariance and correlation coefficients. We will\n",
    "# select the first 10 observations of the variable 'retweet_count'. \n",
    "\n",
    "xs_data2 = tweets_df['retweet_count'][:10]\n",
    "xs_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Covariance tells us whether there is a relation between the deviations of two different variables across observations. It is defined as:\n",
    "\n",
    "$$covariance = \\frac{\\sum_{i=1}^n (x_i - \\bar{x})(y_i - \\bar{y})}{N - 1}$$\n",
    "\n",
    "In other words, first calculate the 'crossproducts' between the two variables (i.e. the first observation of variable $x$ minus the mean of $x$ multiplied by the first observation of $y$ minus the mean of $y$, and so on). Then you add them, and divide by the number of observations (i.e. pairs of observations) minus one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation is computed by scaling the covariance by the standard deviations of the two variables:\n",
    "$$r = \\frac{covariance}{s_xs_y}$$\n",
    "The correlation coefficient is useful because it varies between -1 and 1 regardless of the nature of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Calculate the covariance between the variables xs_data and xs_data2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps: You do not need to code this in Python, simply attempt to describe the steps. For instance, to obtain the covariance of the two variables in our xs_data and the xs_data2 datasets we would: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Calculate, first, the standard deviation of xs_data2 and use this result and the standard deviation of xs_data \n",
    "# to compute the correlation coefficient between the two variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps: You do not need to code this in Python, simply attempt to describe the steps. For instance, to obtain the covariance of the two variables in our xs_data and the xs_data2 datasets we would: ....\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we indicated in the previous session, there are quicker ways to calculate these statistics using already existing functions from existing packages such as Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.06769482],\n",
       "       [0.06769482, 1.        ]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(xs_data,xs_data2) #see the top-right and bottom-left values of the matrix\n",
    "np.corrcoef(xs_data,xs_data2) #same here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Z-score\n",
    "\n",
    "The formula to compute a Z-score for an individual data point given that we know the value of the population mean $\\mu$ and the population standard deviation $\\sigma$ is:\n",
    "$$Z(x) = \\frac{x - \\mu}{\\sigma}$$\n",
    "\n",
    "In other words, you subtract the mean and divide by the standard deviation. \n",
    "In practice we don't have the population mean and hence also standard deviation, so we use the sample mean and standard deviations as our best estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE: Using the mean and standard deviation from Numpy, compute the z-score for our first data points (i.e. 54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First steps: You do not need to code this in Python, simply attempt to describe the steps. For instance, to obtain the z-scores of our xs_data dataset we would: ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SOLUTION: If you input "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quicker way to display all z-scores in Python is to use an already existing function from the Scipy package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.4340973872361027\n"
     ]
    }
   ],
   "source": [
    "zscores = stats.zscore(xs_data)\n",
    "print(zscores[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
